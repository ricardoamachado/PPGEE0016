% Fonte do enunciado citado: :contentReference[oaicite:0]{index=0}
\documentclass[12pt,a4paper]{article}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[brazil]{babel}
\usepackage{lmodern}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{physics}
\usepackage{graphicx}
\graphicspath{{figs/}}
\usepackage{geometry}
\geometry{top=2.5cm, bottom=2.5cm, left=3cm, right=3cm}
\usepackage{fancyhdr}
\usepackage{setspace}
\usepackage{hyperref}
\usepackage{caption}
\usepackage{physics}
\captionsetup{font=small,labelfont=bf}

\onehalfspacing

% cabeçalho/rodapé
\pagestyle{fancy}
\fancyhf{}
\setlength{\headheight}{14.49998pt}
\lhead{Trabalho Otimização (Unidade 1)}
\rhead{Otimização Aplicada em Sistemas de Engenharia}
\cfoot{\thepage}

% Metadados do documento
\title{\LARGE Otimização Aplicada em Sistemas de Engenharia: \\ Comparação de Métodos de 1ª e 2ª Ordem}
\author{
\begin{tabular}{c}
Caio França Santos\\
Shaista\\
Ricardo Messala\\
Ricardo Machado\\
João Lucas
\end{tabular}
}
\date{Salvador -- BA \\ 2025}
\begin{document}

% ---------- CAPA estilo UFBA acadêmica ----------
\begin{titlepage}
    \centering
    \vspace*{1.0 cm}
    {\Large Universidade Federal da Bahia}\\[0.5cm]
    {\large PPGEEC -- Programa de Pós-Graduação em Engenharia Elétrica e Computação}\\[1.5cm]
    {\Large \textbf{Trabalho Otimização (Unidade 1)}}\\[1.5cm]
    {\LARGE \textbf{Otimização Aplicada em Sistemas de Engenharia: \\ Comparação de Métodos de 1ª e 2ª Ordem}}\\[2.0cm]
    \begin{flushleft}
        \textbf{Equipe:}\\[0.2cm]
        Caio França Santos\\
        Shaista\\
        Ricardo Messala\\
        Ricardo Machado\\
        João Lucas
    \end{flushleft}
    \vfill
    \begin{flushright}
        Salvador -- BA\\
        2025
    \end{flushright}
\end{titlepage}

\thispagestyle{empty}
\clearpage

% Sumário
\tableofcontents
\clearpage

% ---------- Introdução ----------
\section{Introdução}
Este relatório apresenta os resultados e a análise comparativa das
implementações dos métodos de otimização solicitados na avaliação intitulada
``Avaliação 1B -- Otimização Aplicada'' (documento fornecido pelo professor)
para os \textbf{Problemas 2 e 4}. O enunciado completo dos problemas
encontra-se no documento da avaliação. Para referência ao enunciado do
professor: Avaliação 1B -- Otimização Aplicada.
:contentReference[oaicite:1]{index=1}

O objetivo geral do trabalho é comparar métodos de primeira ordem (ex.:
Steepest Descent) com métodos de segunda ordem ou quase-segunda ordem (Newton,
Gauss-Newton, BFGS) em termos de:
\begin{itemize}
    \item taxa de convergência (curvas \(\log \lVert g \rVert\) vs iterações);
    \item custo computacional (tempo total e custo por iteração);
    \item robustez frente a ruído e condição inicial;
    \item qualidade da solução para os problemas não-lineares propostos.
\end{itemize}

A seleção dos problemas para este relatório foi:
\begin{center}
    \textbf{Problema 2 -- Estimação de Parâmetros de Circuito (NLS Sintético)} \\
    \textbf{Problema 4 -- Otimização do Rendimento de Conversor DC-DC (Simulação de Perdas)}
\end{center}

Cada seção que segue contém: (i) formulação do problema; (ii) descrição da
geração de dados sintéticos; (iii) implementação dos algoritmos comparados;
(iv) resultados numéricos e gráficos (placeholders); (v) discussão e conclusões
parciais.

\clearpage
\section{Problema 4 -- Otimização do Rendimento de Conversor DC-DC (Simulação de Perdas)}

\subsection{Enunciado (referência)}
O Problema 4 propõe otimizar os parâmetros de controle \(x = [D, f_s]^T\)
(Ciclo de trabalho \(D\) e frequência de chaveamento \(f_s\)) para minimizar
uma função de perdas sintética:
\[
    \min_{D,f_s} L(D,f_s) = \frac{1}{1+D^2} + \frac{f_s}{10000}\sin(10D) + 0.1\,(D-0.5)^2,
\]
com \(0 < D < 1\) e \(f_s>0\). O objetivo é comparar o comportamento de um
método de primeira ordem (Steepest Descent) e um método quase-Newton (BFGS).
(Enunciado: Avaliação 1B -- Otimização Aplicada).
:contentReference[oaicite:3]{index=3}

\subsection{Formulação e escolhas numéricas}
\begin{itemize}
    \item escolha de ponto inicial \((D_0,f_{s0})\) dentro de domínio razoável (ex.:
          \(D_0=0.3, f_{s0}=5000\) Hz);
    \item limites práticos (se desejado, tratar por penalidade externa ou simplesmente
          manter o ponto inicial interior);
    \item normalização das variáveis (opcional) para melhorar condicionamento numérico.
\end{itemize}

\subsection{Métodos implementados}
\begin{enumerate}
    \item \textbf{Steepest Descent (SD)} com busca de passo exata/armijo ou outro esquema de linhas;
    \item \textbf{BFGS} (biblioteca \texttt{scipy.optimize} ou implementação própria) para observar aceleração superlinear na convergência.
\end{enumerate}

\vspace{0.2cm}
\noindent\textbf{Placeholder (figura)}: Trajetória das variáveis \(D\) e \(f_s\) no plano de busca.

\subsection{Fundamentação teórica - Steepest Descent}

O método de otimização Steepest-Descent é fundamentado com base no vetor
gradiente representar a direção de maior crescimento de uma função
$f(\mathbf{x})$ num determinado ponto $\mathbf{x}_k$. Tal comportamento é
justificado em \cite{Antoniou2021-ee} através da Série de Taylor de uma função
de múltiplas variáveis.

\begin{equation}
    f + \Delta f = f(\mathbf{x} + \boldsymbol\delta) \approx f(\mathbf{x}) + \nabla f^T \boldsymbol\delta + \frac{1}{2} \boldsymbol\delta^T H \boldsymbol\delta
\end{equation}

Chamando o vetor gradiente de $\mathbf{g} = \nabla f$ e fazendo
$\norm{\mathbf{\delta}} \to 0$, a variação na função f devido à variação em
$\boldsymbol\delta$ pode ser aproximada por (\ref{eq:delta_f}).

\begin{equation}
    \Delta f \approx \mathbf{g}^T \boldsymbol\delta
    \label{eq:delta_f}
\end{equation}

Dessa forma, a variação $\Delta f$ pode ser aproximada pelo produto escalar
entre o vetor gradiente e o vetor $\boldsymbol\delta$ como descrito na equação
(\ref{eq:delta_f_prod_escalar}), em que $\theta$ representa o ângulo entre os
vetores.

\begin{equation}
    \Delta f \approx \norm{\mathbf{g}} \norm{\boldsymbol\delta} \cos(\theta)
    \label{eq:delta_f_prod_escalar}
\end{equation}

Com base na equação (\ref{eq:delta_f_prod_escalar}), conclui-se que o maior
crescimento na função $f(\mathbf{x})$ ocorre quando $\boldsymbol\delta$ está na
mesma direção do vetor gradiente ($\theta = 0$). De forma análoga, o maior
decrescimento ocorre quando $\boldsymbol\delta$ tem sentido oposto ao gradiente
($\theta = \pi$). As direções de maior crescimento e maior decrescimento são
representadas na figura \ref{fig:dir_gradiente}.

\begin{figure}[h]
    \centering
    \caption{Repreesentação das direções de maior crescimento e maior decrescimento.}
    \includegraphics[width=0.5\textwidth]{./figuras/dir_gradiente.png} \\
    Fonte: \cite{Antoniou2021-ee}
    \label{fig:dir_gradiente}
\end{figure}

O algoritmo de steepest descent consiste em realizar o procedimento iterativo
$\mathbf{x}_{k+1} = \mathbf{x}_{k} - \alpha_k \mathbf{g}_k$, determinando em
cada iteração $k$ o valor de $\alpha_k$ que resulta no maior decrescimento em
$f(\mathbf{x})$, procedimento detalhado na seção \ref{backtracking}. O
algoritmo é executado até $k$ atingir o número máximo de iterações
arbitradas($\mathrm{max_{iter}}$) ou então se a norma do vetor $\alpha_k
    \mathbf{g}_k$ for menor que a tolerância $\epsilon$.

\subsection{Algoritmo de backtracking.} \label{backtracking}

O custo computacional de executar o processo de otimização unidimdensional
(\ref{eq:alpha_otim}) com um algortimo de \emph{line search} exato para cada
iteração do \emph{steepest descent} é elevado. Consequentemente, utiliza-se o
algortimo de \emph{backtracking} para obter um tamanho do passo $\alpha_k$ que
gere um decrescimento suficiente em cada iteração.

\begin{equation}
    \min_\alpha f(\mathbf{x} + \alpha \mathbf{d})
    \label{eq:alpha_otim}
\end{equation}

As condições de Goldstein descritas em \cite{Nocedal2006} definem critérios
para que o tamanho do passo $\alpha_k$ resulte num decrescimento suficiente sem
ser pequeno demais para $0 \leq c < \frac{1}{2}$. A equação (\ref{eq:armijo})
também é chamada de Condição de Armijo \cite{Albanese2023}.

\begin{equation}
    f(\mathbf{x}_k + \alpha_k \mathbf{d_k}) \leq f(\mathbf{x}_k) + c \cdot \alpha_k \mathbf{g_k}^T \mathbf{d_k}
    \label{eq:armijo}
\end{equation}

\begin{equation}
    f(\mathbf{x}_k + \alpha_k \mathbf{d_k}) \geq f(\mathbf{x}_k) + \left(1-c\right) \cdot \alpha_k \mathbf{g_k}^T \mathbf{d_k}
    \label{eq:goldstein}
\end{equation}

Por fim, como a direção adotada no Steepest Descent é contrária ao gradiente
tem-se que $\mathbf{d_k} = -\mathbf{g_k}$. Dessa forma, a condição de Armijo
reduz-se para (\ref{eq:armijo2}).

\begin{equation}
    f(\mathbf{x}_k - \alpha_k \mathbf{g_k}) \leq f(\mathbf{x}_k) - c \cdot \alpha_k \norm{\mathbf{g}_k}^2
    \label{eq:armijo2}
\end{equation}

Com base nas condição de Armijo, define-se o algoritmo de \emph{backtracking
    line search} cujo passo a passo é listado abaixo.\\ Passo 1: Definir o passo
inicial $\alpha$, o fator de contração $\rho$ e o parâmetro de armijo $0 \leq c
    < \frac{1}{2}$. \\ Passo 2: Enquanto $f(\mathbf{x}_k - \alpha \mathbf{g_k}) >
    f(\mathbf{x}_k) - c \cdot \alpha \norm{\mathbf{g}_k}^2$, fazer $\alpha \to
    \frac{\alpha}{\rho}$. \\ Passo 3: Retornar $\alpha_k = \alpha$

\subsection{Resumo do Algoritmo de Steepest Descent.}

Passo 1: Escolher a condição inicial $\mathbf{x}_0$, a tolerância $\epsilon$, o
tamanho do passo inicial $\alpha_0$. \\ Passo 2: Se $k > \mathrm{max_{iter}}$
=> Retornar $\mathbf{x}_k$. Caso contrário => Continuar.\\ Passo 3: Calcular o
gradiente $\mathbf{g}_k = \nabla f(\mathbf{x}_k)$. \\ Passo 4: Encontrar o
$\alpha_k$ que minimiza $f(\mathbf{x}_k - \alpha_k \mathbf{g}_k)$ \\ Passo 5:
Fazer $\mathbf{x}_{k+1} =\mathbf{x}_k -\alpha_k \mathbf{g}_k$ \\ Passo 6: Se
$\norm {\alpha_k \mathbf{g}_k} < \epsilon$ => Retornar $\mathbf{x}_k$. Caso
contrário => Fazer $k \to k+1$ e voltar para o passo 2. \\

\clearpage
\section{Análise Combinada e Custo Computacional}

Inclua aqui tabelas comparativas que contenham, para cada experimento /
semente:
\begin{itemize}
    \item método;
    \item número de iterações;
    \item tempo de execução total (s);
    \item \(\lVert g_{\text{final}}\rVert\);
    \item erro na estimativa (quando aplicável);
    \item número de avaliações de função / gradiente / Hessiana.
\end{itemize}

Exemplo de tabela (placeholder):

% ---------- Conclusões ----------
\clearpage
\section{Considerações finais e próximos passos}

No espaço final do relatório você deve sintetizar:
\begin{itemize}
    \item principais conclusões quantitativas (quem convergiu mais rápido, custo total,
          robustez);
    \item recomendações práticas (quando preferir Gauss-Newton vs Newton; quando BFGS
          compensa);
    \item limitações do estudo (ex.: dimensão pequena, geração de dados sintéticos e
          sensibilidade ao ruído);
    \item sugestões para trabalho futuro (ex.: experimentos com condicionamento,
          diferentes níveis de ruído, implementação em Colab com reprodutibilidade).
\end{itemize}

% ---------- Referências ----------
\clearpage
\bibliographystyle{ieeetr}
\bibliography{refs}

\end{document}
